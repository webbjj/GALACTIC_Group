{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How to use the t-SNE algorithm on APOGEE globular cluster data. \n",
    "##### Steffani Grondin (September 23, 2022)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "%pip install sklearn\n",
    "%pip install shapely"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notes for this program"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My parameter list is different from Steffani's. My param list is shown below:\\\\\\\\\n",
    "param_list = ['# APOGEE_ID_', 'GAIAEDR3_SOURCE_ID', 'GAIAEDR3_PARALLAX', 'GAIAEDR3_PARALLAX_ERROR', 'RA', 'DEC', 'GAIAEDR3_PMRA', 'GAIAEDR3_PMRA_ERROR', 'GAIAEDR3_PMDEC', 'GAIAEDR3_PMDEC_ERROR', 'GAIAEDR3_DR2_RADIAL_VELOCITY', 'GAIAEDR3_DR2_RADIAL_VELOCITY_ERROR', 'SNR', 'FE_H', 'FE_H_ERR', 'C_FE', 'C_FE_ERR', 'CI_FE', 'CI_FE_ERR', 'N_FE', 'N_FE_ERR', 'O_FE', 'O_FE_ERR', 'MG_FE', 'MG_FE_ERR', 'AL_FE', 'AL_FE_ERR', 'SI_FE', 'SI_FE_ERR', 'P_FE', 'P_FE_ERR', 'S_FE', 'S_FE_ERR', 'K_FE', 'K_FE_ERR', 'CA_FE', 'CA_FE_ERR', 'TI_FE', 'TI_FE_ERR', 'TIII_FE', 'TIII_FE_ERR', 'V_FE', 'V_FE_ERR', 'CR_FE', 'CR_FE_ERR', 'MN_FE', 'MN_FE_ERR', 'CO_FE', 'CO_FE_ERR', 'NI_FE', 'NI_FE_ERR']\\\\\\\\\n",
    "\n",
    "So basically the RA index is 4, DEC index is 5, RV index is 10, and the first chemical abundance is at 13. The chemical abundances follow Steffani's form (e.g. abundance1, abundance1_error, abundance2, abundance2_error, etc.). What I did was make the standardizing step for both tSNE and UMAP take in the index of the first chemical abundance and from there it automatically adds 2 for each chem abundance going up.\\\\\\\\\n",
    "\n",
    "Basically if you use my param_list it'll work. The param_list variable is just a list of strings of the index titles, I have a function somewhere that grabs the data for those indices.\\\\\\\\\n",
    "\n",
    "For each GC, we just need the ra, dec, rhm_deg (rhm depends on dist I think).\\\\\n",
    "There are global parameters for all GCs as well, so the parameter list, fov, and chemical abundance starting index.\\\\\\\\\n",
    "\n",
    "LMK if shit dont work and there's probably something I forgot to explain."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 0: Import the necessary packages/algorithms."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "# General analysis/plotting packages:\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import math\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib import rc\n",
    "plt.rcParams['mathtext.fontset'] = 'stix'\n",
    "plt.rcParams['font.family'] = 'STIXGeneral'\n",
    "from collections import Counter\n",
    "\n",
    "# Specific t-SNE/visualization packages:\n",
    "from sklearn.manifold import TSNE\n",
    "from shapely.geometry import Point, Polygon\n",
    "\n",
    "# UMAP shit\n",
    "# Import UMAP\n",
    "import umap.umap_ as umap\n",
    "\n",
    "# Try using SKLEARN's StandardScaler to standardize the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# I/O\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 1: Load in the clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load in selected star cluster\n",
    "Input RA and DEC and the program will load in all the stars within a $10^o$ by $10^o$ FOV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Read in APOGEE CSV file'''\n",
    "\n",
    "apogee_filt = pd.read_csv('data/APOGEEDR17_GAIAEDR3_filter.csv', delimiter=',')\n",
    "apogee_nofilt = pd.read_csv('data/APOGEEDR17_GAIAEDR3_noflagfilter.csv', delimiter=',')\n",
    "GC_db = pd.read_csv('data/GC_catalogue_fullparams.csv', delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "hide-input"
    ]
   },
   "outputs": [],
   "source": [
    "### Finding stars within a set FOV of the GC centre\n",
    "def find_cluster_stars(ra, dec, fov, df):\n",
    "    stars = []\n",
    "    for count, i in enumerate(df['RA'].values):\n",
    "        if i >= ra - fov and i <= ra + fov and df['DEC'].values[count] >= dec - fov and df['DEC'].values[count] <= dec + fov:\n",
    "            stars.append(df.loc[count])\n",
    "            \n",
    "    print(len(stars), 'stars in a 10x10 fov of the GC')\n",
    "\n",
    "    ra_arr = np.empty(len(stars), dtype=float)\n",
    "    dec_arr = np.empty(len(stars), dtype=float)\n",
    "    for count, i in enumerate(stars):\n",
    "        ra_arr[count] = i['RA']\n",
    "        dec_arr[count] = i['DEC']\n",
    "\n",
    "    plt.figure(figsize=(10,10))\n",
    "    plt.plot(ra_arr, dec_arr, 'ok', linestyle='none', markersize=1, label='Stars')\n",
    "    plt.plot(ra, dec, 'or', linestyle='none', markersize=5, label='GC centre')\n",
    "    plt.xlabel('RA')\n",
    "    plt.ylabel('DEC')\n",
    "    plt.xlim(ra - fov - 1, ra + fov + 1)\n",
    "    plt.ylim(dec - fov - 1, dec + fov + 1)\n",
    "    plt.show()\n",
    "    \n",
    "    return stars\n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating list of stars into lists by parameter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_star_list(stars, parameters):\n",
    "    param_dict = {}\n",
    "    for i in parameters:\n",
    "        if str(i) == '# APOGEE_ID_':\n",
    "            param_dict[str(i)] = np.empty(len(stars), dtype=object)\n",
    "        else:\n",
    "            param_dict[str(i)] = np.empty(len(stars))\n",
    "    for count,i in enumerate(stars):\n",
    "        for j in parameters:\n",
    "            param_dict[str(j)][count] = i[str(j)]\n",
    "            \n",
    "    return param_dict\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Separating the dictionary values into a columns list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_cols(GC_param, parameters):\n",
    "    cols = []\n",
    "    for i in range(len(GC_param)):\n",
    "        cols.append(GC_param[str(parameters[i])])\n",
    "    \n",
    "    return cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Master GC load function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_load(ra, dec, fov, dataset, params):\n",
    "    stars_found = find_cluster_stars(ra, dec, fov, dataset)\n",
    "    GC_dict = split_star_list(stars_found, params)\n",
    "    GC_cols = split_cols(GC_dict, param_list)\n",
    "    \n",
    "    return [GC_dict, GC_cols]\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: Filter the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter 1 for data: Removing all stars without PM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pm_filter(GC_dict, GC_cols):\n",
    "    ### Filter 1: Remove stars that do not have proper motion values. ###\n",
    "    pm_filter_nan = np.isnan(GC_dict['GAIAEDR3_PMRA'])\n",
    "    pm_filter = np.where(pm_filter_nan==False)\n",
    "    data_pmfilter = []\n",
    "    for i in GC_cols:\n",
    "        x = np.array(i)[pm_filter]\n",
    "        data_pmfilter.append(x)\n",
    "    #print(\"There are {} stars in our sample after the proper motion filtering.\".format(len(data_pmfilter[0])))\n",
    "    \n",
    "    return data_pmfilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter 2 for data: Removing all stars that do not have chemical abundances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def chem_filter(data_pmfilter, init_abundance_index):\n",
    "    ### Filter 2: Remove stars that do not have data for all 19 abundances. ###\n",
    "    abundance_filter = np.where((data_pmfilter[init_abundance_index] > -9999) & (data_pmfilter[init_abundance_index + 2] > -9999) & (data_pmfilter[init_abundance_index + 4]  > -9999)\n",
    "                                & (data_pmfilter[init_abundance_index + 6]  > -9999) & (data_pmfilter[ init_abundance_index + 8]  > -9999) & (data_pmfilter[init_abundance_index + 10]  > -9999)\n",
    "                                & (data_pmfilter[init_abundance_index + 12]  > -9999) & (data_pmfilter[init_abundance_index + 14]  > -9999) & (data_pmfilter[init_abundance_index + 16]  > -9999)\n",
    "                                & (data_pmfilter[init_abundance_index + 18]  > -9999) & (data_pmfilter[init_abundance_index + 20]  > -9999) & (data_pmfilter[init_abundance_index + 22]  > -9999)\n",
    "                                & (data_pmfilter[init_abundance_index + 24]  > -9999) & (data_pmfilter[init_abundance_index + 26]  > -9999) & (data_pmfilter[init_abundance_index + 28]  > -9999)\n",
    "                                & (data_pmfilter[init_abundance_index + 30]  > -9999) & (data_pmfilter[init_abundance_index + 32]  > -9999) & (data_pmfilter[init_abundance_index + 34]  > -9999)\n",
    "                                & (data_pmfilter[init_abundance_index + 36]  > -9999))\n",
    "\n",
    "    data_abundancefilter = []\n",
    "    for i in data_pmfilter:\n",
    "        y = np.array(i)[abundance_filter]\n",
    "        data_abundancefilter.append(y)\n",
    "    #print(\"There are {} stars in our sample after the abundance filtering.\".format(len(data_abundancefilter[0])))\n",
    "    \n",
    "    return data_abundancefilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter 3 for data: Removing all duplicate spectra"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# changed all indices of 0 to 4 (RA) and 23 to 12 (SNR)\n",
    "def dup_filter(data_abundancefilter):\n",
    "    d =  Counter(data_abundancefilter[4])\n",
    "    #print(d)\n",
    "    duplicates = [k for k, v in d.items() if v > 1]\n",
    "    a_list = np.array(range(0, len(duplicates)))\n",
    "    max_SNR_array = []\n",
    "\n",
    "    for i in a_list:\n",
    "        indices = np.where(data_abundancefilter[4] == duplicates[i])\n",
    "        snr_val = data_abundancefilter[12][indices]\n",
    "        maximum = max(snr_val)\n",
    "        # 4 is RA, 12 is SNR\n",
    "        index_maximum = np.where((data_abundancefilter[4] == duplicates[i]) & (data_abundancefilter[12] == maximum))\n",
    "        #print(index_maximum[4])\n",
    "        index_maximum = int(index_maximum[4])\n",
    "        max_SNR_array.append(index_maximum)\n",
    "\n",
    "    idx_sort = np.argsort(data_abundancefilter[4])\n",
    "    sorted_ra_array = data_abundancefilter[4][idx_sort]\n",
    "    vals, idx_start, count = np.unique(sorted_ra_array, return_counts=True, return_index=True)\n",
    "    res = np.split(idx_sort, idx_start[1:])\n",
    "    vals = vals[count == 1]\n",
    "    listtest =  np.array(range(0, len(vals)))\n",
    "\n",
    "    unique_array = []\n",
    "    for i in listtest:\n",
    "        unique_val = np.where(vals[i] == data_abundancefilter[4])\n",
    "        unique_val = int(unique_val[0])\n",
    "        unique_array.append(unique_val)\n",
    "\n",
    "    #print(\"There are {} stars that do not have duplicate spectra.\".format(len(unique_array)))\n",
    "    #print(\"There are {} stars that have multiple spectra, in which we select highest SNR.\".format(len(max_SNR_array)))\n",
    "    \n",
    "    if len(max_SNR_array) != 0:\n",
    "        duplicates_filter = np.concatenate((unique_array, max_SNR_array))\n",
    "        sortedarray = np.sort(duplicates_filter)\n",
    "\n",
    "        data_duplicatesfilter = []\n",
    "        for i in data_abundancefilter:\n",
    "            z = np.array(i)[duplicates_filter]\n",
    "            data_duplicatesfilter.append(z)\n",
    "\n",
    "        #print(\"There are {} stars in our sample after removing sources with duplicate spectra.\".format(len(data_duplicatesfilter[0])))\n",
    "    \n",
    "    else:\n",
    "        #print('There were no duplicate spectra.')\n",
    "        data_duplicatesfilter = data_abundancefilter\n",
    "    \n",
    "    return data_duplicatesfilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filter 4 for data: Removing all low SNR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SNR_filter(data_duplicatesfilter):\n",
    "    SNR_filter = np.where(data_duplicatesfilter[12] > 50)\n",
    "    data_snrfilter = []\n",
    "    for i in data_duplicatesfilter:\n",
    "        a = np.array(i)[SNR_filter]\n",
    "        data_snrfilter.append(a)\n",
    "\n",
    "    #print(\"There are {} stars in our sample after removing sources with low SNR.\".format(len(data_snrfilter[0])))\n",
    "\n",
    "    #print(data_snrfilter[12])\n",
    "    return data_snrfilter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Master filter function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_filter(GC_dict, GC_cols):\n",
    "    M3_pm_filter = pm_filter(GC_dict, GC_cols)\n",
    "    M3_abundance_filter = chem_filter(M3_pm_filter, 13)\n",
    "    M3_duplicates_filter = dup_filter(M3_abundance_filter)\n",
    "    M3_SNR_filter = SNR_filter(M3_duplicates_filter)\n",
    "    \n",
    "    print('\\nThe final amount of stars in our sample is:', len(M3_SNR_filter[0]))\n",
    "    return M3_SNR_filter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 3: Define parameters for your GC of interest. \n",
    "\n",
    "These parameters are taken from the Baumgardt & Hilker (2018) catalogue: https://people.smp.uq.edu.au/HolgerBaumgardt/globular/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 4: Define a control group of cluster members.\n",
    "\n",
    "We must define a control group of likely cluster members of M3 so we can see where these stars end up in the t-SNE projection. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def control_group(data_filter, ra, dec, rhm_deg):\n",
    "# Select all the stars within some radius of the cluster:\n",
    "    def in_circle(center_x, center_y, radius, x, y):\n",
    "        square_dist = (center_x - x) ** 2 + (center_y - y) ** 2\n",
    "        return square_dist <= (radius) ** 2\n",
    "\n",
    "    ra_filtered = data_filter[4]\n",
    "    dec_filtered = data_filter[5]\n",
    "\n",
    "    # Select stars within 8 * r,hm (useful for large enough sample of probable cluster members):\n",
    "    in_halfmass = in_circle(ra, dec, 8*rhm_deg, ra_filtered, dec_filtered)\n",
    "    indices_control = np.where(in_halfmass==True)\n",
    "\n",
    "    '''# larger rhm\n",
    "    in_halfmass_10 = in_circle(ra, dec, 10*rhm_deg, ra_filtered, dec_filtered)\n",
    "    indices_control_10 = np.where(in_halfmass_10==True)\n",
    "\n",
    "    # smaller rhm\n",
    "    in_halfmass_6 = in_circle(ra, dec, 6*rhm_deg, ra_filtered, dec_filtered)\n",
    "    indices_control_6 = np.where(in_halfmass_6==True)'''\n",
    "\n",
    "    controlgroup = []\n",
    "    for i in data_filter:\n",
    "        b = np.array(i)[indices_control]\n",
    "        controlgroup.append(b)\n",
    "\n",
    "    '''controlgroup_10 = []\n",
    "    for i in data_filter:\n",
    "        b_10 = np.array(i)[indices_control_10]\n",
    "        controlgroup_10.append(b_10)\n",
    "\n",
    "    controlgroup_6 = []\n",
    "    for i in data_filter:\n",
    "        b_6 = np.array(i)[indices_control_6]\n",
    "        controlgroup_6.append(b_6)'''\n",
    "\n",
    "    # Example control group parameters: \n",
    "    ra_control = controlgroup[0]\n",
    "    dec_control = controlgroup[1]\n",
    "\n",
    "    print(\"There are {} stars in our GC control group.\".format(len(ra_control)))\n",
    "\n",
    "    '''print(\"There are {} stars in our M3 control group w/ size 10.\".format(len(controlgroup_10)))\n",
    "\n",
    "    print(\"There are {} stars in our M3 control group w/ size 6.\".format(len(controlgroup_6)))'''\n",
    "    \n",
    "    return [indices_control]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### STEP 5: Run t-SNE on the control group and full filtered sample of APOGEE DR17 stars.\n",
    "\n",
    "First, we standardize the data to ensure that no elements dominate or skew the t-SNE run. We want to include 19 chemical abundances and radial velocities in our run.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize_data(data_filter, param_dict):\n",
    "    '''\n",
    "    Takes in a dictionary of parameters with the parameter name as the key and the index in the APOGEE file as the key value.\n",
    "    '''\n",
    "    \n",
    "    pretsne_array = []\n",
    "    params_arr = []\n",
    "    \n",
    "    for key in param_dict:\n",
    "        pretsne_array.append(data_filter[param_dict[key]])\n",
    "        params_arr.append(key)\n",
    "    \n",
    "    pretsne_array = np.array(pretsne_array)\n",
    "    \n",
    "    standardized = []\n",
    "    \n",
    "    for i in pretsne_array:\n",
    "        #print(i)\n",
    "        mean, sigma = np.nanmean(i), np.nanstd(i)\n",
    "        #print(mean)\n",
    "        norm = (i - mean) / sigma\n",
    "        standardized.append(norm)\n",
    "        \n",
    "    print('The chosen parameters for the ML algorithms were:', params_arr)\n",
    "    return standardized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we apply the t-SNE algorithm via scikit-learn to reduce the dimensionality of the data from 20-D to 2-D."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tSNE_alg(standardized_array, indices_control):\n",
    "    # Transpose the standardized + filtered array:\n",
    "    standardized_array_transpose = np.transpose(standardized_array)\n",
    "\n",
    "    # Run t-SNE on the transposed array:\n",
    "    tsne_init = TSNE(n_components=2)\n",
    "    tsne_2d = tsne_init.fit_transform(standardized_array_transpose)\n",
    "\n",
    "    # Get t-SNE outputs for complete filtered dataset:\n",
    "    t_SNE_dimX = tsne_2d[:, 0]\n",
    "    t_SNE_dimY = tsne_2d[:, 1]\n",
    "\n",
    "    # Get t-SNE outputs for control group:\n",
    "    tsne_dimX_control = t_SNE_dimX[indices_control]\n",
    "    tsne_dimY_control = t_SNE_dimY[indices_control]\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    ax.scatter(t_SNE_dimX, t_SNE_dimY, s=1, c='gray', label='APOGEE DR17 stars')\n",
    "    ax.scatter(tsne_dimX_control , tsne_dimY_control, s=45, edgecolor='k', c='hotpink', label='Control Group')\n",
    "    ax.set_xlabel(\"t-SNE X-Dimension\", fontsize=16)\n",
    "    ax.set_ylabel(\"t-SNE Y-Dimension\", fontsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=16)\n",
    "    ax.legend(fontsize=16, loc=1)\n",
    "    plt.show()\n",
    "    \n",
    "    print('Total: ', len(t_SNE_dimX), 'Control: ', len(tsne_dimX_control[0]))\n",
    "    \n",
    "    return [t_SNE_dimX, t_SNE_dimY, tsne_dimX_control[0], tsne_dimY_control[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_tSNE(data_filter, param_dict, indices_control):\n",
    "    standardize = standardize_data(data_filter, param_dict)\n",
    "    \n",
    "    return tSNE_alg(standardize, indices_control)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### UMAP function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_UMAP(data_filter, param_dict, indices_control):\n",
    "    standardize = standardize_data(data_filter, param_dict)\n",
    "    \n",
    "    reducer = umap.UMAP()\n",
    "    embedding = reducer.fit_transform(standardize)\n",
    "    # Transpose the standardized + filtered array:\n",
    "    standardized_array_transpose = np.transpose(standardize)\n",
    "\n",
    "    # Run t-SNE on the transposed array:\n",
    "    reducer = umap.UMAP()\n",
    "    embedding = reducer.fit_transform(standardized_array_transpose)\n",
    "\n",
    "    # Get t-SNE outputs for complete filtered dataset:\n",
    "    umap_dimX = embedding[:, 0]\n",
    "    umap_dimY = embedding[:, 1]\n",
    "\n",
    "    # Get t-SNE outputs for control group:\n",
    "    umap_dimX_control = umap_dimX[indices_control]\n",
    "    umap_dimY_control = umap_dimY[indices_control]\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(8,6))\n",
    "    ax.scatter(umap_dimX, umap_dimY, s=1, c='gray', label='APOGEE DR17 stars')\n",
    "    ax.scatter(umap_dimX_control , umap_dimY_control, s=45, edgecolor='k', c='hotpink', label='Control Group')\n",
    "    ax.set_xlabel(\"UMAP X-Dimension\", fontsize=16)\n",
    "    ax.set_ylabel(\"UMAP Y-Dimension\", fontsize=16)\n",
    "    ax.tick_params(axis='both', which='major', labelsize=16)\n",
    "    ax.tick_params(axis='both', which='minor', labelsize=16)\n",
    "    ax.legend(fontsize=16)\n",
    "    plt.show()\n",
    "    print('Total:',len(umap_dimX),'control:',len(umap_dimX_control[0]))\n",
    "    \n",
    "    return [umap_dimX, umap_dimY, umap_dimX_control[0], umap_dimY_control[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function below is depricated. New function above"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Choosing which parameters to use for tSNE and UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ask_input_param(param):\n",
    "    inp = input('Do you want to keep ' + param + ' as a parameter? [y/n]')\n",
    "    if inp.lower() == 'y':\n",
    "        return True\n",
    "    elif inp.lower() == 'n':\n",
    "        return False\n",
    "    else:\n",
    "        print('Not a valid input, trying again')\n",
    "        return ask_input_param(param)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_params(master_param_dict):\n",
    "    parameter_dict = {}\n",
    "\n",
    "    for i in master_param_dict:\n",
    "        if ask_input_param(i):\n",
    "            parameter_dict[i] = master_param_dict[i]\n",
    "            \n",
    "    return parameter_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Taking in datasheet and name and automatically getting the parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def GC_params(GC_name, db):\n",
    "    GC = db.loc[db['Cluster'] == GC_name].iloc[0]\n",
    "    name = GC['Cluster']\n",
    "    ra = GC['RA']\n",
    "    dec = GC['DEC']\n",
    "    mass = GC['Mass']\n",
    "    rhm = GC[' rhm   '] # will steff fix this, nobody knows\n",
    "    rt = GC['rt']\n",
    "    rho_c = GC['rho_c']\n",
    "    sig0 = GC['sig0']\n",
    "    vesc = GC['vesc']\n",
    "    c = GC['c']\n",
    "    d_Sun = GC[' d_Sun  '] * 1e3\n",
    "    rhm_deg = math.degrees(math.atan(rhm / d_Sun))\n",
    "    \n",
    "    return ra, dec, rhm_deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def input_GC_name(db):\n",
    "    GC_name = input(\"Please enter the GC name according to Steff's catalogue:\")\n",
    "    if db.loc[db['Cluster'] == GC_name].empty:\n",
    "        print('Not a valid name, double check and try again')\n",
    "        return input_GC_name(db)\n",
    "    else:\n",
    "        return GC_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master function (automatic version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_func_auto(GC_name, master_param_dict, fov, db, dataset, params, ML):\n",
    "    print('Processing:', GC_name)\n",
    "    ML_values = {0, 1, 2}    \n",
    "    if ML not in ML_values:\n",
    "        raise ValueError('ML index not one of %r.' % ML_values)\n",
    "    \n",
    "    # getting GC parameteters\n",
    "    ra, dec, rhm_deg = GC_params(GC_name, db)\n",
    "    \n",
    "    # loading\n",
    "    GC_dict, GC_cols = master_load(ra, dec, fov, dataset, params)\n",
    "    \n",
    "    # filtering\n",
    "    GC_filter_data = master_filter(GC_dict, GC_cols)\n",
    "    \n",
    "    if GC_filter_data[0].size == 0:\n",
    "        print(\"This shit don't got no stars bruh\")\n",
    "        return [None, None, None, None, None, None, None, None]\n",
    "    \n",
    "    else:\n",
    "        # control grouping\n",
    "        GC_indices_control = control_group(GC_filter_data, ra, dec, rhm_deg)\n",
    "\n",
    "        # choosing parameters\n",
    "        param_dict = master_param_dict\n",
    "\n",
    "        if ML == 0:\n",
    "            # tSNEing\n",
    "            tSNE_X, tSNE_Y, tSNE_control_X, tSNE_control_Y = master_tSNE(GC_filter_data, param_dict, GC_indices_control)\n",
    "\n",
    "            # UMAPing\n",
    "            UMAP_X, UMAP_Y, UMAP_control_X, UMAP_control_Y = master_UMAP(GC_filter_data, param_dict, GC_indices_control)\n",
    "\n",
    "            print('Done!\\n')\n",
    "            return [tSNE_X, tSNE_Y, tSNE_control_X, tSNE_control_Y, UMAP_X, UMAP_Y, UMAP_control_X, UMAP_control_Y]\n",
    "\n",
    "        elif ML == 1:\n",
    "            # tSNEing\n",
    "            tSNE_X, tSNE_Y, tSNE_control_X, tSNE_control_Y = master_tSNE(GC_filter_data, param_dict, GC_indices_control)\n",
    "\n",
    "            print('Done!\\n')\n",
    "            return [tSNE_X, tSNE_Y, tSNE_control_X, tSNE_control_Y, None, None, None, None]\n",
    "\n",
    "        elif ML == 2:\n",
    "            # UMAPing\n",
    "            UMAP_X, UMAP_Y, UMAP_control_X, UMAP_control_Y = master_UMAP(GC_filter_data, param_dict, GC_indices_control)\n",
    "\n",
    "            print('Done!\\n')\n",
    "            return [None, None, None, None, UMAP_X, UMAP_Y, UMAP_control_X, UMAP_control_Y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Master function (manual version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def master_func_manual(GC_name, master_param_dict, fov, db, dataset, params, ML):\n",
    "    print('Processing:', GC_name)\n",
    "    ML_values = {0, 1, 2}    \n",
    "    if ML not in ML_values:\n",
    "        raise ValueError('ML index not one of %r.' % ML_values)\n",
    "    \n",
    "    # getting GC parameteters\n",
    "    #GC_name = input_GC_name(db)\n",
    "    ra, dec, rhm_deg = GC_params(GC_name, db)\n",
    "    \n",
    "    # loading\n",
    "    GC_dict, GC_cols = master_load(ra, dec, fov, dataset, params)\n",
    "    \n",
    "    # filtering\n",
    "    GC_filter_data = master_filter(GC_dict, GC_cols)\n",
    "    \n",
    "    if GC_filter_data[0].size == 0:\n",
    "        print(\"This shit don't got no stars bruh\")\n",
    "        return [None, None, None, None, None, None, None, None]\n",
    "    \n",
    "    else:\n",
    "        # control grouping\n",
    "        GC_indices_control = control_group(GC_filter_data, ra, dec, rhm_deg)\n",
    "\n",
    "        # choosing parameters\n",
    "        param_dict = choose_params(master_param_dict)\n",
    "\n",
    "        if ML == 0:\n",
    "            # tSNEing\n",
    "            tSNE_X, tSNE_Y, tSNE_control_X, tSNE_control_Y = master_tSNE(GC_filter_data, param_dict, GC_indices_control)\n",
    "\n",
    "            # UMAPing\n",
    "            UMAP_X, UMAP_Y, UMAP_control_X, UMAP_control_Y = master_UMAP(GC_filter_data, param_dict, GC_indices_control)\n",
    "\n",
    "            print('Done!\\n')\n",
    "            return [tSNE_X, tSNE_Y, tSNE_control_X, tSNE_control_Y, UMAP_X, UMAP_Y, UMAP_control_X, UMAP_control_Y]\n",
    "\n",
    "        elif ML == 1:\n",
    "            # tSNEing\n",
    "            tSNE_X, tSNE_Y, tSNE_control_X, tSNE_control_Y = master_tSNE(GC_filter_data, param_dict, GC_indices_control)\n",
    "\n",
    "            print('Done!\\n')\n",
    "            return [tSNE_X, tSNE_Y, tSNE_control_X, tSNE_control_Y, None, None, None, None]\n",
    "\n",
    "        elif ML == 2:\n",
    "            # UMAPing\n",
    "            UMAP_X, UMAP_Y, UMAP_control_X, UMAP_control_Y = master_UMAP(GC_filter_data, param_dict, GC_indices_control)\n",
    "\n",
    "            print('Done!\\n')\n",
    "            return [None, None, None, None, UMAP_X, UMAP_Y, UMAP_control_X, UMAP_control_Y]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Global GC params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_list = ['# APOGEE_ID_', 'GAIAEDR3_SOURCE_ID', 'GAIAEDR3_PARALLAX', 'GAIAEDR3_PARALLAX_ERROR',\n",
    "              'RA', 'DEC', 'GAIAEDR3_PMRA', 'GAIAEDR3_PMRA_ERROR', 'GAIAEDR3_PMDEC', 'GAIAEDR3_PMDEC_ERROR', \n",
    "              'VHELIO_AVG', 'VERR', 'SNR',\n",
    "              'FE_H', 'FE_H_ERR', 'C_FE', 'C_FE_ERR', 'CI_FE', 'CI_FE_ERR', 'N_FE', 'N_FE_ERR',\n",
    "              'O_FE', 'O_FE_ERR', 'MG_FE', 'MG_FE_ERR', 'AL_FE', 'AL_FE_ERR', 'SI_FE', 'SI_FE_ERR',\n",
    "              'P_FE', 'P_FE_ERR', 'S_FE', 'S_FE_ERR', 'K_FE', 'K_FE_ERR', 'CA_FE', 'CA_FE_ERR',\n",
    "              'TI_FE', 'TI_FE_ERR', 'TIII_FE', 'TIII_FE_ERR', 'V_FE', 'V_FE_ERR', 'CR_FE', 'CR_FE_ERR',\n",
    "              'MN_FE', 'MN_FE_ERR', 'CO_FE', 'CO_FE_ERR', 'NI_FE', 'NI_FE_ERR']\n",
    "\n",
    "abundance_index = 13 # index where the first chemical abundance starts\n",
    "RV_index = 10 # where the radial velocity index is (NOTE: USE VHELIO_AVG NOT THE STUPID GAIA ONE)\n",
    "PMRA_index = 6 # PMRA index\n",
    "PMDEC_index = 8 # PMDEC index\n",
    "\n",
    "# dictionary of all relevant parameters we could ever want for tSNE and UMAP\n",
    "# the abundances should skip every other one due to it being [chem1, chem1_err, chem2, chem2_err, etc.]\n",
    "all_param_dict = {'FE_H': abundance_index,\n",
    "                 'C_FE': abundance_index + 2,\n",
    "                 'CI_FE': abundance_index + 4,\n",
    "                 'N_FE': abundance_index + 6,\n",
    "                 'O_FE': abundance_index + 8,\n",
    "                 'MG_FE': abundance_index + 10,\n",
    "                 'AL_FE': abundance_index + 12,\n",
    "                 'SI_FE': abundance_index + 14,\n",
    "                 'P_FE': abundance_index + 16,\n",
    "                 'S_FE': abundance_index + 18,\n",
    "                 'K_FE': abundance_index + 20,\n",
    "                 'CA_FE': abundance_index + 22,\n",
    "                 'TI_FE': abundance_index + 24,\n",
    "                 'TIII_FE': abundance_index + 26,\n",
    "                 'V_FE': abundance_index + 28,\n",
    "                 'CR_FE': abundance_index + 30,\n",
    "                 'MN_FE': abundance_index + 32,\n",
    "                 'CO_FE': abundance_index + 34,\n",
    "                 'NI_FE': abundance_index + 36,\n",
    "                 'RV': RV_index,\n",
    "                 'PMRA': PMRA_index,\n",
    "                 'PMDEC': PMDEC_index}\n",
    "\n",
    "\n",
    "fov = 5 # field of view (note: for x by x, use fov = x/2)\n",
    "ML_index = 0 # 0 for both tSNE and UMAP, 1 for only tSNE, 2 for only UMAP, any other value will raise an error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reading in from the GC database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GC_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GC_name_list = GC_db.loc[:, 'Cluster']\n",
    "GC_stars_dict = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GC_ra_list = GC_db.loc[:, 'RA']\n",
    "GC_dec_list = GC_db.loc[:, 'DEC']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "GC_stars_dict[GC_name_list[0]] = master_func(GC_name_list[0], all_param_dict, fov, GC_db, apogee_nofilt, param_list, ML_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for count, i in enumerate(GC_name_list):\n",
    "    GC_stars_dict[i] = master_func_auto(i, all_param_dict, fov, GC_db, apogee_nofilt, param_list, ML_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(GC_stars_dict))\n",
    "\n",
    "GC_name_list = []\n",
    "control_stars_list = []\n",
    "total_stars_list = []\n",
    "\n",
    "for key in GC_stars_dict:\n",
    "    GC_name_list.append(key)\n",
    "    control_stars_list.append(len(GC_stars_dict[key][2]))\n",
    "    total_stars_list.append(len(GC_stars_dict[key][0]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "point_size_list = []\n",
    "for i in control_stars_list:\n",
    "    if i <= 25:\n",
    "        point_size_list.append(500 + i * 50)\n",
    "    elif i > 25 and i <= 50:\n",
    "        point_size_list.append(1500 + i * 50)\n",
    "    elif i > 50 and i <= 100:\n",
    "        point_size_list.append(3000 + i * 50)\n",
    "    elif i > 100:\n",
    "        point_size_list.append(5000 + i * 50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 50}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "plt.figure(figsize=(60,40))\n",
    "plt.plot(apogee_nofilt.RA, apogee_nofilt.DEC.values, 'ok', markersize=1, alpha=0.5)\n",
    "plt.scatter(GC_ra_list, GC_dec_list, color='r', s=point_size_list, edgecolor='k', linewidth=3)\n",
    "plt.xlabel('RA [deg]')\n",
    "plt.ylabel('DEC [deg]')\n",
    "plt.title('Plot of the APOGEE dataset stars and GC cluster central location based on control group size')\n",
    "plt.savefig('GC_map.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Warning: Only run this block below if you have a beefy computer or if you wanna experience MS slideshow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "font = {'family' : 'DejaVu Sans',\n",
    "        'weight' : 'bold',\n",
    "        'size'   : 10}\n",
    "\n",
    "plt.rc('font', **font)\n",
    "\n",
    "fig, ax = plt.subplots(23, 14, figsize=(230, 200))\n",
    "for i in range(23):\n",
    "    for j in range(7):\n",
    "        # tSNE\n",
    "        ax[i, 2 * j].scatter(GC_stars_dict[GC_name_list[i + j * 14]][0], GC_stars_dict[GC_name_list[i + j * 14]][1], s=1, c='gray') # all\n",
    "        ax[i, 2 * j].scatter(GC_stars_dict[GC_name_list[i + j * 14]][2], GC_stars_dict[GC_name_list[i + j * 14]][3], s=45, edgecolor='k', c='hotpink') # control\n",
    "        ax[i, 2 * j].set_title(GC_name_list[i + j * 14] + ' tSNE')\n",
    "        ax[i, 2 * j].set_xlabel('tSNE X')\n",
    "        ax[i, 2 * j].set_ylabel('tSNE Y')\n",
    "        # UMAP\n",
    "        ax[i, 2 * j + 1].scatter(GC_stars_dict[GC_name_list[i + j * 14]][4], GC_stars_dict[GC_name_list[i + j * 14]][5], s=1, c='gray') # all\n",
    "        ax[i, 2 * j + 1].scatter(GC_stars_dict[GC_name_list[i + j * 14]][6], GC_stars_dict[GC_name_list[i + j * 14]][7], s=45, edgecolor='k', c='hotpink') # control\n",
    "        ax[i, 2 * j + 1].set_title(GC_name_list[i + j * 14] + ' UMAP')\n",
    "        ax[i, 2 * j + 1].set_xlabel('UMAP X')\n",
    "        ax[i, 2 * j + 1].set_ylabel('UMAP Y')\n",
    "        \n",
    "        \n",
    "plt.tight_layout()\n",
    "plt.savefig('all_ML.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(total_stars_list, bins=20, color='k')\n",
    "plt.hist(control_stars_list, bins=5, color='r', alpha=0.5)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(12,8))\n",
    "plt.plot(GC_name_list, total_stars_list, 'ok', markersize=1)\n",
    "plt.plot(GC_name_list, control_stars_list, 'or', markersize=1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## old stuff"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for GCs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# M3 (NGC 5272)\n",
    "ra_M3 = 205.54842 # [deg]\n",
    "dec_M3 = 28.37728 # [deg]\n",
    "dist_M3 = 10180  # [pc]\n",
    "rt_M3 = 159.0339  # [pc] -- tidal radius @ apogalacticon\n",
    "rhm_M3 = 6.34  # [pc]\n",
    "rhm_M3_deg = math.degrees(math.atan(rhm_M3 / dist_M3))  # deg\n",
    "pmra_M3 = -0.152  # [mas/yr]\n",
    "pmdec_M3 = -2.670  # [mas/yr]\n",
    "\n",
    "# M13 (NGC 6205)\n",
    "ra_M13 = 250.42181\n",
    "dec_M13 = 36.45986\n",
    "dist_M13 = 7420\n",
    "rt_M13 = 8640\n",
    "rhm_M13 = 5.26\n",
    "rhm_M13_deg = math.degrees(math.atan(rhm_M13 / dist_M13))  # deg\n",
    "\n",
    "# M2 (NGC 7089)\n",
    "ra_M2 = 323.36258\n",
    "dec_M2 = -0.82325\n",
    "dist_M2 = 11690\n",
    "rt_M2 = 10540\n",
    "rhm_M2 = 4.77\n",
    "rhm_M2_deg = math.degrees(math.atan(rhm_M2 / dist_M2))  # deg\n",
    "\n",
    "# M12 (NGC 6218)\n",
    "ra_M12 = 251.80907\n",
    "dec_M12 = -1.94853\n",
    "dist_M12 = 5110\n",
    "rt_M12 = 4570\n",
    "rhm_M12 = 4.05\n",
    "rhm_M12_deg = math.degrees(math.atan(rhm_M12 / dist_M12))  # deg\n",
    "\n",
    "# M10 (NGC 6254)\n",
    "ra_M10 = 254.28772\n",
    "dec_M10 = -4.10031\n",
    "dist_M10 = 5070\n",
    "rt_M10 = 4350\n",
    "rhm_M10 = 4.81\n",
    "rhm_M10_deg = math.degrees(math.atan(rhm_M10 / dist_M10))  # deg\n",
    "\n",
    "# NGC 6397\n",
    "ra_NGC6397 = 265.17538\n",
    "dec_NGC6397 = -53.67434\n",
    "dist_NGC6397 = 2480\n",
    "rt_NGC6397 = 6010\n",
    "rhm_NGC6397 = 3.90\n",
    "rhm_NGC6397_deg = math.degrees(math.atan(rhm_NGC6397 / dist_NGC6397))  # deg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(40,40))\n",
    "plt.plot(apogee_nofilt['RA'].values, apogee_nofilt['DEC'].values, 'ok', linewidth=1, linestyle='none')\n",
    "plt.plot(ra_M3, dec_M3, 'or', markersize=25)\n",
    "plt.plot(ra_M13, dec_M13, 'or', markersize=25)\n",
    "plt.plot(ra_M2, dec_M2, 'or', markersize=25)\n",
    "plt.plot(ra_M10, dec_M10, 'or', markersize=25)\n",
    "plt.plot(ra_NGC6397, dec_NGC6397, 'or', markersize=25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M3\n",
    "NGC_5272"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M3_tSNE_X, M3_tSNE_Y, M3_tSNE_control_X, M3_tSNE_control_Y, M3_UMAP_X, M3_UMAP_Y, M3_UMAP_control_X, M3_UMAP_control_Y = master_func(all_param_dict, fov, GC_db, apogee_nofilt, param_list, ML_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M13"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M13_tSNE_X, M13_tSNE_Y, M13_tSNE_control_X, M13_tSNE_control_Y, M13_UMAP_X, M13_UMAP_Y, M13_UMAP_control_X, M13_UMAP_control_Y = master_func(ra_M13, dec_M13, rhm_M13_deg, all_param_dict, fov, apogee_nofilt, param_list, ML_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "M2_tSNE_X, M2_tSNE_Y, M2_tSNE_control_X, M2_tSNE_control_Y, M2_UMAP_X, M2_UMAP_Y, M2_UMAP_control_X, M2_UMAP_control_Y = master_func(ra_M2, dec_M2, rhm_M2_deg, all_param_dict, fov, apogee_nofilt, param_list, ML_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M12"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M12_tSNE_X, M12_tSNE_Y, M12_tSNE_control_X, M12_tSNE_control_Y, M12_UMAP_X, M12_UMAP_Y, M12_UMAP_control_X, M12_UMAP_control_Y = master_func(ra_M12, dec_M12, rhm_M12_deg, all_param_dict, fov, apogee_nofilt, param_list, ML_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### M10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "M10_tSNE_X, M10_tSNE_Y, M10_tSNE_control_X, M10_tSNE_control_Y, M10_UMAP_X, M10_UMAP_Y, M10_UMAP_control_X, M10_UMAP_control_Y = master_func(ra_M10, dec_M10, rhm_M10_deg, all_param_dict, fov, apogee_nofilt, param_list, ML_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### NGC6397"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NGC6397_tSNE_X, NGC6397_tSNE_Y, NGC6397_tSNE_control_X, NGC6397_tSNE_control_Y, NGC6397_UMAP_X, NGC6397_UMAP_Y, NGC6397_UMAP_control_X, NGC6397_UMAP_control_Y = master_func(ra_NGC6397, dec_NGC6397, rhm_NGC6397_deg, all_param_dict, fov, apogee_nofilt, param_list, ML_index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is random shit ive been playing around with, you can ignore or continue playing around with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing Perplexity (default 30)\n",
    "related to # of nearby neighbours. Not sure what specifically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### Perplexity changing\n",
    "# Transpose the standardized + filtered array:\n",
    "standardized_array_transpose = np.transpose(standardized_array)\n",
    "\n",
    "# Run t-SNE on the transposed array:\n",
    "# perplexity list (default 30)\n",
    "perp_list = [5, 10, 15, 20, 25, 35, 40, 45, 50]\n",
    "t_SNE_dimX_perp = []\n",
    "t_SNE_dimY_perp = []\n",
    "tsne_dimX_control_perp = []\n",
    "tsne_dimY_control_perp = []\n",
    "for i in perp_list:\n",
    "    tsne_init_perp = TSNE(n_components=2, perplexity=i)\n",
    "    tsne_2d_perp = tsne_init_perp.fit_transform(standardized_array_transpose)\n",
    "\n",
    "    # Get t-SNE outputs for complete filtered dataset:\n",
    "    t_SNE_dimX_perp.append(tsne_2d_perp[:, 0])\n",
    "    t_SNE_dimY_perp.append(tsne_2d_perp[:, 1])\n",
    "\n",
    "    # Get t-SNE outputs for control group:\n",
    "    tsne_dimX_control_perp.append(t_SNE_dimX_perp[-1][indices_control])\n",
    "    tsne_dimY_control_perp.append(t_SNE_dimY_perp[-1][indices_control])\n",
    "    \n",
    "    print('t_SNE done for perp =', i)\n",
    "\n",
    "print('t_SNE done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig_perp, ax = plt.subplots(3, 3, figsize=(40,32))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax[i,j].scatter(t_SNE_dimX_perp[i + 3 * j], t_SNE_dimY_perp[i + 3 * j], s=1, c='gray', label='APOGEE DR17 stars')\n",
    "        ax[i,j].scatter(tsne_dimX_control_perp[i + 3 * j], tsne_dimY_control_perp[i + 3 * j], s=45, edgecolor='k', c='hotpink', label='M3 Control Group')\n",
    "        ax[i,j].set_xlabel(\"t-SNE X-Dimension\", fontsize=16)\n",
    "        ax[i,j].set_ylabel(\"t-SNE Y-Dimension\", fontsize=16)\n",
    "        ax[i,j].tick_params(axis='both', which='major', labelsize=16)\n",
    "        ax[i,j].tick_params(axis='both', which='minor', labelsize=16)\n",
    "        ax[i,j].set_title('Graph for perp =' + str(perp_list[i + 3 * j]))\n",
    "        ax[i,j].legend(fontsize=16, loc=1)\n",
    "        #print('Total: ', len(t_SNE_dimX_list[i + 3*j]), 'Control: ', len(tsne_dimX_control_list[i + 3 * j]))\n",
    "plt.tight_layout()\n",
    "plt.savefig('tSNE_perp')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like the higher the perplexity, the more tightly grouped together the control stars. After 20 there seems to be a drop off in terms of cluster tightness increase. Running the same code doesn't yield the same graphs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing early exaggeration (default 12)\n",
    "controls tightness of natural clusters and how much space will be in between them?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "### early exaggeration changing\n",
    "# Transpose the standardized + filtered array:\n",
    "standardized_array_transpose = np.transpose(standardized_array)\n",
    "\n",
    "# Run t-SNE on the transposed array:\n",
    "# early exaggeration list (default 12.)\n",
    "exg_list = [4., 8., 16., 20., 24., 28., 32., 36., 40.]\n",
    "t_SNE_dimX_exg = []\n",
    "t_SNE_dimY_exg = []\n",
    "tsne_dimX_control_exg = []\n",
    "tsne_dimY_control_exg = []\n",
    "for i in exg_list:\n",
    "    tsne_init_exg = TSNE(n_components=2, perplexity=i)\n",
    "    tsne_2d_exg = tsne_init_exg.fit_transform(standardized_array_transpose)\n",
    "\n",
    "    # Get t-SNE outputs for complete filtered dataset:\n",
    "    t_SNE_dimX_exg.append(tsne_2d_exg[:, 0])\n",
    "    t_SNE_dimY_exg.append(tsne_2d_exg[:, 1])\n",
    "\n",
    "    # Get t-SNE outputs for control group:\n",
    "    tsne_dimX_control_exg.append(t_SNE_dimX_exg[-1][indices_control])\n",
    "    tsne_dimY_control_exg.append(t_SNE_dimY_exg[-1][indices_control])\n",
    "    \n",
    "    print('t_SNE done for exg =', i)\n",
    "\n",
    "print('t_SNE done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig_exg, ax = plt.subplots(3, 3, figsize=(40,32))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax[i,j].scatter(t_SNE_dimX_exg[i + 3 * j], t_SNE_dimY_exg[i + 3 * j], s=1, c='gray', label='APOGEE DR17 stars')\n",
    "        ax[i,j].scatter(tsne_dimX_control_exg[i + 3 * j], tsne_dimY_control_exg[i + 3 * j], s=45, edgecolor='k', c='hotpink', label='M3 Control Group')\n",
    "        ax[i,j].set_xlabel(\"t-SNE X-Dimension\", fontsize=16)\n",
    "        ax[i,j].set_ylabel(\"t-SNE Y-Dimension\", fontsize=16)\n",
    "        ax[i,j].tick_params(axis='both', which='major', labelsize=16)\n",
    "        ax[i,j].tick_params(axis='both', which='minor', labelsize=16)\n",
    "        ax[i,j].set_title('Graph for early exg =' + str(exg_list[i + 3 * j]))\n",
    "        ax[i,j].legend(fontsize=16, loc=1)\n",
    "        #print('Total: ', len(t_SNE_dimX_exg[i + 3*j]), 'Control: ', len(tsne_dimX_control_exg[i + 3 * j]))\n",
    "plt.tight_layout()\n",
    "plt.savefig('tSNE_exg')\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems like higher early exaggeration leads to tighter groups. Just like perplexity, there seems to be a falloff in group tightness increase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Changing learning rate (default 200)\n",
    "something to do with step size and optimization for ML algorithms i think"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### early exaggeration changing\n",
    "# Transpose the standardized + filtered array:\n",
    "standardized_array_transpose = np.transpose(standardized_array)\n",
    "\n",
    "# Run t-SNE on the transposed array:\n",
    "# early exaggeration list (default 12.)\n",
    "learn_list = [10., 100., 300., 400., 500., 600., 700., 800., 900.]\n",
    "t_SNE_dimX_learn = []\n",
    "t_SNE_dimY_learn = []\n",
    "tsne_dimX_control_learn = []\n",
    "tsne_dimY_control_learn = []\n",
    "for i in learn_list:\n",
    "    tsne_init_learn = TSNE(n_components=2, learning_rate=i)\n",
    "    tsne_2d_learn = tsne_init_learn.fit_transform(standardized_array_transpose)\n",
    "\n",
    "    # Get t-SNE outputs for complete filtered dataset:\n",
    "    t_SNE_dimX_learn.append(tsne_2d_learn[:, 0])\n",
    "    t_SNE_dimY_learn.append(tsne_2d_learn[:, 1])\n",
    "\n",
    "    # Get t-SNE outputs for control group:\n",
    "    tsne_dimX_control_learn.append(t_SNE_dimX_learn[-1][indices_control])\n",
    "    tsne_dimY_control_learn.append(t_SNE_dimY_learn[-1][indices_control])\n",
    "    \n",
    "    print('t_SNE done for learn =', i)\n",
    "\n",
    "print('t_SNE done')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "fig_learn, ax = plt.subplots(3, 3, figsize=(40,32))\n",
    "for i in range(3):\n",
    "    for j in range(3):\n",
    "        ax[i,j].scatter(t_SNE_dimX_learn[i + 3 * j], t_SNE_dimY_learn[i + 3 * j], s=1, c='gray', label='APOGEE DR17 stars')\n",
    "        ax[i,j].scatter(tsne_dimX_control_learn[i + 3 * j], tsne_dimY_control_learn[i + 3 * j], s=45, edgecolor='k', c='hotpink', label='M3 Control Group')\n",
    "        ax[i,j].set_xlabel(\"t-SNE X-Dimension\", fontsize=16)\n",
    "        ax[i,j].set_ylabel(\"t-SNE Y-Dimension\", fontsize=16)\n",
    "        ax[i,j].tick_params(axis='both', which='major', labelsize=16)\n",
    "        ax[i,j].tick_params(axis='both', which='minor', labelsize=16)\n",
    "        ax[i,j].set_title('Graph for learning rate =' + str(exg_list[i + 3 * j]))\n",
    "        ax[i,j].legend(fontsize=16, loc=1)\n",
    "        #print('Total: ', len(t_SNE_dimX_exg[i + 3*j]), 'Control: ', len(tsne_dimX_control_exg[i + 3 * j]))\n",
    "plt.tight_layout()\n",
    "plt.savefig('tSNE_learn')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Not too much noticable change surprisingly."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OVerall remarks\n",
    "\n",
    "Seems to have a similar structure each time, just different control group locations and orientations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Improving the Dimensionality Reduction\n",
    "Fine tune the hyper-parameters:\n",
    "- understand how the different hyper-parameters affect the data\n",
    "- what combination of hyper-parameters achieve the best separation of the control group? to acheive the best \n",
    "\n",
    "Helpful Papers:\n",
    "\n",
    "https://distill.pub/2016/misread-tsne/ \n",
    "\n",
    "https://towardsdatascience.com/how-to-tune-hyperparameters-of-tsne-7c0596a18868 \n",
    "\n",
    "Dimensional Reduction Astronomy Example:\n",
    "https://arxiv.org/pdf/2210.02471.pdf\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
